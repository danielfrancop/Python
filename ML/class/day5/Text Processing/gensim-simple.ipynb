{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",\".*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"text8.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' anarchism originated as a term of abuse first used against early working class radicals including t'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' collectively and that goods be distributed by need not labor an early anarchist communist was josep'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(10000)\n",
    "f.read(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.Text8Corpus('./text8.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-07 15:50:32,994 : INFO : collecting all words and their counts\n",
      "2019-02-07 15:50:32,998 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-02-07 15:50:37,169 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2019-02-07 15:50:37,169 : INFO : Loading a fresh vocabulary\n",
      "2019-02-07 15:50:37,371 : INFO : effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "2019-02-07 15:50:37,371 : INFO : effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "2019-02-07 15:50:37,555 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2019-02-07 15:50:37,555 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2019-02-07 15:50:37,555 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "2019-02-07 15:50:37,738 : INFO : estimated required memory for 71290 words and 200 dimensions: 149709000 bytes\n",
      "2019-02-07 15:50:37,738 : INFO : resetting layer weights\n",
      "2019-02-07 15:50:38,467 : INFO : training model with 3 workers on 71290 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-07 15:50:39,465 : INFO : EPOCH 1 - PROGRESS: at 8.35% examples, 1035094 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:40,471 : INFO : EPOCH 1 - PROGRESS: at 16.81% examples, 1044594 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:41,478 : INFO : EPOCH 1 - PROGRESS: at 24.63% examples, 1021506 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:42,482 : INFO : EPOCH 1 - PROGRESS: at 32.04% examples, 999492 words/s, in_qsize 5, out_qsize 1\n",
      "2019-02-07 15:50:43,482 : INFO : EPOCH 1 - PROGRESS: at 39.68% examples, 992091 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:44,479 : INFO : EPOCH 1 - PROGRESS: at 47.50% examples, 989798 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:45,491 : INFO : EPOCH 1 - PROGRESS: at 55.79% examples, 996680 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:46,482 : INFO : EPOCH 1 - PROGRESS: at 63.96% examples, 999809 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-07 15:50:47,498 : INFO : EPOCH 1 - PROGRESS: at 72.37% examples, 1005017 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:48,499 : INFO : EPOCH 1 - PROGRESS: at 81.01% examples, 1009782 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:49,517 : INFO : EPOCH 1 - PROGRESS: at 89.48% examples, 1013840 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-07 15:50:50,516 : INFO : EPOCH 1 - PROGRESS: at 98.06% examples, 1017793 words/s, in_qsize 4, out_qsize 0\n",
      "2019-02-07 15:50:50,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 15:50:50,748 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 15:50:50,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 15:50:50,753 : INFO : EPOCH - 1 : training on 17005207 raw words (12506493 effective words) took 12.3s, 1018289 effective words/s\n",
      "2019-02-07 15:50:51,750 : INFO : EPOCH 2 - PROGRESS: at 8.35% examples, 1035863 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:52,750 : INFO : EPOCH 2 - PROGRESS: at 16.87% examples, 1044110 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:53,766 : INFO : EPOCH 2 - PROGRESS: at 25.16% examples, 1042122 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:54,767 : INFO : EPOCH 2 - PROGRESS: at 33.45% examples, 1042741 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:55,782 : INFO : EPOCH 2 - PROGRESS: at 41.92% examples, 1044290 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:56,782 : INFO : EPOCH 2 - PROGRESS: at 50.26% examples, 1044936 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:57,782 : INFO : EPOCH 2 - PROGRESS: at 58.14% examples, 1036141 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:58,782 : INFO : EPOCH 2 - PROGRESS: at 66.02% examples, 1029648 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:50:59,798 : INFO : EPOCH 2 - PROGRESS: at 73.90% examples, 1024854 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:00,787 : INFO : EPOCH 2 - PROGRESS: at 82.13% examples, 1023120 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:01,811 : INFO : EPOCH 2 - PROGRESS: at 90.18% examples, 1021257 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:02,812 : INFO : EPOCH 2 - PROGRESS: at 98.12% examples, 1017963 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:03,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 15:51:03,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 15:51:03,041 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 15:51:03,042 : INFO : EPOCH - 2 : training on 17005207 raw words (12506806 effective words) took 12.3s, 1017951 effective words/s\n",
      "2019-02-07 15:51:04,030 : INFO : EPOCH 3 - PROGRESS: at 7.23% examples, 896491 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:05,034 : INFO : EPOCH 3 - PROGRESS: at 15.17% examples, 940730 words/s, in_qsize 4, out_qsize 0\n",
      "2019-02-07 15:51:06,043 : INFO : EPOCH 3 - PROGRESS: at 22.99% examples, 952990 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:07,059 : INFO : EPOCH 3 - PROGRESS: at 31.28% examples, 973870 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:08,066 : INFO : EPOCH 3 - PROGRESS: at 39.51% examples, 985598 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:09,077 : INFO : EPOCH 3 - PROGRESS: at 47.85% examples, 994259 words/s, in_qsize 5, out_qsize 1\n",
      "2019-02-07 15:51:10,076 : INFO : EPOCH 3 - PROGRESS: at 55.97% examples, 998048 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:11,087 : INFO : EPOCH 3 - PROGRESS: at 63.96% examples, 997442 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:12,090 : INFO : EPOCH 3 - PROGRESS: at 72.08% examples, 999036 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-07 15:51:13,093 : INFO : EPOCH 3 - PROGRESS: at 79.66% examples, 991253 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:14,111 : INFO : EPOCH 3 - PROGRESS: at 86.89% examples, 982197 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-07 15:51:15,120 : INFO : EPOCH 3 - PROGRESS: at 94.36% examples, 977528 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:15,839 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 15:51:15,844 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 15:51:15,850 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 15:51:15,851 : INFO : EPOCH - 3 : training on 17005207 raw words (12505676 effective words) took 12.8s, 976423 effective words/s\n",
      "2019-02-07 15:51:16,846 : INFO : EPOCH 4 - PROGRESS: at 7.70% examples, 955129 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:17,859 : INFO : EPOCH 4 - PROGRESS: at 15.76% examples, 976300 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:18,877 : INFO : EPOCH 4 - PROGRESS: at 23.93% examples, 989232 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:19,891 : INFO : EPOCH 4 - PROGRESS: at 31.51% examples, 977933 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:20,896 : INFO : EPOCH 4 - PROGRESS: at 39.45% examples, 981408 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:21,909 : INFO : EPOCH 4 - PROGRESS: at 47.03% examples, 974484 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:22,913 : INFO : EPOCH 4 - PROGRESS: at 54.97% examples, 977094 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:23,930 : INFO : EPOCH 4 - PROGRESS: at 63.08% examples, 980100 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:24,927 : INFO : EPOCH 4 - PROGRESS: at 71.19% examples, 983798 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:25,940 : INFO : EPOCH 4 - PROGRESS: at 79.60% examples, 988376 words/s, in_qsize 4, out_qsize 0\n",
      "2019-02-07 15:51:26,944 : INFO : EPOCH 4 - PROGRESS: at 87.95% examples, 992034 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:27,948 : INFO : EPOCH 4 - PROGRESS: at 96.41% examples, 996533 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:28,381 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 15:51:28,387 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 15:51:28,390 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 15:51:28,391 : INFO : EPOCH - 4 : training on 17005207 raw words (12505425 effective words) took 12.5s, 997856 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-07 15:51:29,396 : INFO : EPOCH 5 - PROGRESS: at 7.88% examples, 968598 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:30,406 : INFO : EPOCH 5 - PROGRESS: at 15.70% examples, 969865 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:31,396 : INFO : EPOCH 5 - PROGRESS: at 23.52% examples, 973608 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:32,407 : INFO : EPOCH 5 - PROGRESS: at 31.51% examples, 982655 words/s, in_qsize 4, out_qsize 0\n",
      "2019-02-07 15:51:33,410 : INFO : EPOCH 5 - PROGRESS: at 39.33% examples, 982729 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:34,416 : INFO : EPOCH 5 - PROGRESS: at 47.62% examples, 990276 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:35,429 : INFO : EPOCH 5 - PROGRESS: at 55.73% examples, 993674 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:36,434 : INFO : EPOCH 5 - PROGRESS: at 63.96% examples, 997904 words/s, in_qsize 4, out_qsize 0\n",
      "2019-02-07 15:51:37,448 : INFO : EPOCH 5 - PROGRESS: at 72.13% examples, 999160 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:38,457 : INFO : EPOCH 5 - PROGRESS: at 80.42% examples, 1000372 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:39,472 : INFO : EPOCH 5 - PROGRESS: at 88.77% examples, 1002788 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:40,478 : INFO : EPOCH 5 - PROGRESS: at 97.06% examples, 1004844 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-07 15:51:40,813 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-07 15:51:40,830 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-07 15:51:40,834 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-07 15:51:40,834 : INFO : EPOCH - 5 : training on 17005207 raw words (12506449 effective words) took 12.4s, 1005394 effective words/s\n",
      "2019-02-07 15:51:40,835 : INFO : training on a 85026035 raw words (62530849 effective words) took 62.4s, 1002641 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-07 12:42:04,443 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6522661447525024)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.7833876609802246),\n",
       " ('wife', 0.7306841015815735),\n",
       " ('daughter', 0.6938297748565674)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['girl', 'father'], ['boy'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'he' is to 'his' as 'she' is to 'her'\n",
      "'big' is to 'bigger' as 'bad' is to 'worse'\n",
      "'going' is to 'went' as 'being' is to 'was'\n"
     ]
    }
   ],
   "source": [
    "more_examples = [\"he his she\", \"big bigger bad\", \"going went being\"]\n",
    "for example in more_examples:\n",
    "     a, b, x = example.split()\n",
    "     predicted = model.most_similar([x, b], [a])[0][0]\n",
    "     print (\"'%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
