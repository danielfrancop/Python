{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn1 = \"hello and welcome to the machine learning course\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=nltk.word_tokenize(sn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'and', 'welcome', 'to', 'the', 'machine', 'learning', 'course']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('welcome', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'NN'),\n",
       " ('course', 'NN')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn2 = \"lets go to eat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lets', 'NNS'), ('go', 'VBP'), ('to', 'TO'), ('eat', 'VB')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(sn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('car.n.01'), Synset('car.n.02'), Synset('car.n.03'), Synset('car.n.04'), Synset('cable_car.n.01')]\n"
     ]
    }
   ],
   "source": [
    "# https://wordnet.princeton.edu\n",
    "car_synsets = nc.wordnet.synsets('car')\n",
    "print (car_synsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = nc.wordnet.synset('dog.n.01')\n",
    "cat = nc.wordnet.synset('cat.n.01')\n",
    "\n",
    "similarity_score1 = dog.path_similarity(cat)\n",
    "similarity_score2 = dog.wup_similarity(cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n",
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "import nltk.book \n",
    "nltk.book.text1.concordance(\"monstrous\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13721"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.book.text1.count(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('textproc.txt','r').read()\n",
    "tok=nltk.word_tokenize(f)\n",
    "t1 = nltk.Text(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.count('python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "... ) • Two terms with a relation ( python , machine learning ) • Numbers To p\n",
      "s To process to text we can use : • Python string type • Regular expressions •\n",
      "ar expressions • Dedicated packages Python Strings We can use python string me\n",
      " packages Python Strings We can use python string methods for simple operation\n",
      " very simple , you can read more in python official documentation Regular Expr\n"
     ]
    }
   ],
   "source": [
    "t1.concordance('python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'!': 1,\n",
       "          '#': 15,\n",
       "          \"'\": 40,\n",
       "          \"''\": 6,\n",
       "          \"''.join\": 1,\n",
       "          \"'111\": 1,\n",
       "          \"'456\": 1,\n",
       "          \"'888\": 1,\n",
       "          \"'Ending\": 1,\n",
       "          \"'Matched\": 1,\n",
       "          \"'Starting\": 1,\n",
       "          \"'The\": 1,\n",
       "          \"'bers\": 1,\n",
       "          \"'code\": 1,\n",
       "          \"'english\": 1,\n",
       "          \"'have\": 1,\n",
       "          \"'hello\": 4,\n",
       "          \"'how\": 1,\n",
       "          \"'num\": 1,\n",
       "          \"'see\": 1,\n",
       "          \"'some\": 1,\n",
       "          \"'stopwords\": 1,\n",
       "          \"'strin.g\": 1,\n",
       "          \"'string\": 4,\n",
       "          \"'today\": 1,\n",
       "          \"'with\": 1,\n",
       "          '(': 51,\n",
       "          ')': 51,\n",
       "          '+': 3,\n",
       "          ',': 145,\n",
       "          '-': 1,\n",
       "          '.': 8,\n",
       "          '...': 2,\n",
       "          '.fit': 1,\n",
       "          '.sum': 1,\n",
       "          '.Â': 1,\n",
       "          '0': 46,\n",
       "          '0-9': 3,\n",
       "          '1': 44,\n",
       "          '1,20': 1,\n",
       "          '10': 4,\n",
       "          '107': 1,\n",
       "          '11': 1,\n",
       "          '2': 8,\n",
       "          '20': 2,\n",
       "          '3': 8,\n",
       "          '3,4,5': 1,\n",
       "          '4': 7,\n",
       "          '5': 3,\n",
       "          '6': 4,\n",
       "          '6,9': 1,\n",
       "          '7': 2,\n",
       "          '8': 2,\n",
       "          '888': 3,\n",
       "          '9': 2,\n",
       "          ':': 28,\n",
       "          ':+\\\\s': 1,\n",
       "          '=': 18,\n",
       "          '==': 2,\n",
       "          '>': 8,\n",
       "          'As': 1,\n",
       "          'CV': 1,\n",
       "          'CVs': 1,\n",
       "          'Check': 1,\n",
       "          'Count': 1,\n",
       "          'CountVectorizer': 2,\n",
       "          'Dedicated': 2,\n",
       "          'Examples': 1,\n",
       "          'Expressions': 1,\n",
       "          'Find': 3,\n",
       "          'For': 1,\n",
       "          'I': 2,\n",
       "          'In': 2,\n",
       "          'It': 3,\n",
       "          'Language': 1,\n",
       "          'Learning': 1,\n",
       "          'Machine': 1,\n",
       "          'NLP': 2,\n",
       "          'NLTK': 2,\n",
       "          'NLTKis': 1,\n",
       "          'Natural': 1,\n",
       "          'Now': 1,\n",
       "          'Numbers': 1,\n",
       "          'One': 3,\n",
       "          'Out': 2,\n",
       "          'Packages': 1,\n",
       "          'Processing': 1,\n",
       "          'Python': 2,\n",
       "          'Regular': 3,\n",
       "          'Removing': 2,\n",
       "          'Scikit-learn': 1,\n",
       "          'Some': 1,\n",
       "          'Sometimes': 1,\n",
       "          'Split': 1,\n",
       "          'Splitting': 1,\n",
       "          'Strings': 1,\n",
       "          'Text': 1,\n",
       "          'The': 3,\n",
       "          'This': 1,\n",
       "          'To': 3,\n",
       "          'Two': 1,\n",
       "          'Using': 1,\n",
       "          'We': 3,\n",
       "          'Word': 2,\n",
       "          'You': 3,\n",
       "          '[': 20,\n",
       "          ']': 20,\n",
       "          '``': 1,\n",
       "          'a': 19,\n",
       "          'about': 1,\n",
       "          'all': 5,\n",
       "          'allstopwords': 2,\n",
       "          'alpha': 1,\n",
       "          'also': 1,\n",
       "          'an': 2,\n",
       "          'and': 12,\n",
       "          'andÂ': 1,\n",
       "          'are': 2,\n",
       "          'array': 3,\n",
       "          'at': 2,\n",
       "          'automatic': 1,\n",
       "          'axis': 1,\n",
       "          'axis=0': 1,\n",
       "          'based': 2,\n",
       "          'be': 3,\n",
       "          'between': 1,\n",
       "          'blog': 1,\n",
       "          'brown': 1,\n",
       "          'build': 3,\n",
       "          'building': 1,\n",
       "          'but': 1,\n",
       "          'buy': 1,\n",
       "          'by': 1,\n",
       "          'camel': 1,\n",
       "          'can': 10,\n",
       "          'char': 3,\n",
       "          'characters': 2,\n",
       "          'classify': 1,\n",
       "          'close': 1,\n",
       "          'code': 1,\n",
       "          'colon': 1,\n",
       "          'comma': 1,\n",
       "          'complete': 1,\n",
       "          'complex': 1,\n",
       "          'conditions': 1,\n",
       "          'convert': 1,\n",
       "          'count': 4,\n",
       "          'create': 1,\n",
       "          'data': 3,\n",
       "          'day': 1,\n",
       "          \"day'\": 1,\n",
       "          'description': 1,\n",
       "          'digits': 1,\n",
       "          'do': 1,\n",
       "          'document': 3,\n",
       "          'documentation': 1,\n",
       "          'documents': 2,\n",
       "          \"dog'\": 1,\n",
       "          'download': 1,\n",
       "          'ends': 1,\n",
       "          'engine': 1,\n",
       "          'engineering': 1,\n",
       "          'etc': 1,\n",
       "          'example': 3,\n",
       "          'examples': 1,\n",
       "          'existing': 1,\n",
       "          'expressions': 3,\n",
       "          'extract': 1,\n",
       "          'far': 1,\n",
       "          'feature': 1,\n",
       "          'features': 1,\n",
       "          'field': 3,\n",
       "          'find': 1,\n",
       "          'first': 2,\n",
       "          'followed': 1,\n",
       "          'for': 15,\n",
       "          'fox': 2,\n",
       "          'fox|camel': 1,\n",
       "          'free': 1,\n",
       "          'from': 7,\n",
       "          'good': 1,\n",
       "          'guide': 1,\n",
       "          'handling': 1,\n",
       "          'has': 1,\n",
       "          'have': 6,\n",
       "          'hello': 4,\n",
       "          'helps': 2,\n",
       "          'here': 1,\n",
       "          'huge': 1,\n",
       "          'if': 3,\n",
       "          'import': 8,\n",
       "          'in': 9,\n",
       "          'index': 2,\n",
       "          'information': 1,\n",
       "          'input': 1,\n",
       "          'inputmessage': 1,\n",
       "          'inputmessage.split': 1,\n",
       "          'intro': 1,\n",
       "          'is': 5,\n",
       "          'isÂ': 1,\n",
       "          'it': 9,\n",
       "          'job': 1,\n",
       "          'jumps': 1,\n",
       "          'keywords': 1,\n",
       "          'language': 1,\n",
       "          'lazy': 1,\n",
       "          'learn': 1,\n",
       "          'learning': 3,\n",
       "          'look': 2,\n",
       "          'looking': 1,\n",
       "          'm': 2,\n",
       "          'm.end': 1,\n",
       "          'm.groups': 1,\n",
       "          'm.start': 1,\n",
       "          'machine': 2,\n",
       "          'manipulate': 1,\n",
       "          'manipulation': 1,\n",
       "          'many': 4,\n",
       "          'me': 1,\n",
       "          'mess': 2,\n",
       "          'methods': 1,\n",
       "          'models': 1,\n",
       "          'modules': 1,\n",
       "          'more': 5,\n",
       "          'multiple': 1,\n",
       "          'natural': 1,\n",
       "          'need': 3,\n",
       "          'new': 1,\n",
       "          'newmess': 3,\n",
       "          'nice': 2,\n",
       "          'nltk': 1,\n",
       "          'nltk.corpus': 1,\n",
       "          'nltk.download': 1,\n",
       "          'nopunc': 1,\n",
       "          'not': 4,\n",
       "          \"num+bers'\": 2,\n",
       "          'numbers': 4,\n",
       "          \"numbers'\": 1,\n",
       "          'numpy': 1,\n",
       "          'of': 1,\n",
       "          'offer': 1,\n",
       "          'official': 2,\n",
       "          'on': 7,\n",
       "          'one': 1,\n",
       "          'ones': 1,\n",
       "          'only': 1,\n",
       "          'operations': 1,\n",
       "          'options': 1,\n",
       "          'or': 3,\n",
       "          'our': 1,\n",
       "          'outmessage': 2,\n",
       "          'over': 1,\n",
       "          'package': 6,\n",
       "          'packages': 2,\n",
       "          'part': 1,\n",
       "          'plus': 1,\n",
       "          'popular': 1,\n",
       "          'post': 2,\n",
       "          'preprocessing': 2,\n",
       "          'print': 10,\n",
       "          'process': 1,\n",
       "          'processing': 1,\n",
       "          'punct': 1,\n",
       "          'punctuation': 1,\n",
       "          'python': 3,\n",
       "          'quick': 2,\n",
       "          'quick|slow': 1,\n",
       "          'r': 1,\n",
       "          're': 4,\n",
       "          're.findall': 1,\n",
       "          're.search': 1,\n",
       "          're.split': 1,\n",
       "          're.sub': 1,\n",
       "          'read': 1,\n",
       "          'regex': 1,\n",
       "          'regular': 1,\n",
       "          'related': 1,\n",
       "          'relation': 1,\n",
       "          'remove': 1,\n",
       "          'removing': 1,\n",
       "          'result': 1,\n",
       "          'results': 1,\n",
       "          'rules': 1,\n",
       "          'sale': 1,\n",
       "          'scikit-learnis': 1,\n",
       "          'search': 1,\n",
       "          'second': 1,\n",
       "          'see': 4,\n",
       "          'separator': 2,\n",
       "          'set': 1,\n",
       "          'simple': 4,\n",
       "          'single': 1,\n",
       "          'site': 1,\n",
       "          'sklearn.feature_extraction.text': 2,\n",
       "          'slow': 1,\n",
       "          'so': 4,\n",
       "          'some': 4,\n",
       "          'some111': 3,\n",
       "          'something': 1,\n",
       "          'spaces': 1,\n",
       "          'start': 1,\n",
       "          'stop': 2,\n",
       "          'stopwords': 2,\n",
       "          'stopwords.words': 1,\n",
       "          'str1': 6,\n",
       "          'string': 8,\n",
       "          'string.ascii_letters': 1,\n",
       "          'string.digits': 1,\n",
       "          'string.hexdigits': 1,\n",
       "          'string.punctuation': 1,\n",
       "          'strings': 2,\n",
       "          'sub': 1,\n",
       "          'substring': 1,\n",
       "          'sum': 1,\n",
       "          'supervised': 1,\n",
       "          'system': 1,\n",
       "          'terms': 1,\n",
       "          'testy': 2,\n",
       "          'text': 5,\n",
       "          'that': 3,\n",
       "          'the': 10,\n",
       "          'them': 1,\n",
       "          'this': 1,\n",
       "          'to': 13,\n",
       "          'today': 1,\n",
       "          'tr': 1,\n",
       "          'tr.toarray': 2,\n",
       "          'tr=trans.transform': 1,\n",
       "          'trans': 1,\n",
       "          'trans.vocabulary_': 1,\n",
       "          'transform': 1,\n",
       "          'txt': 6,\n",
       "          'type': 1,\n",
       "          \"u'all\": 1,\n",
       "          \"u'and\": 1,\n",
       "          \"u'are\": 1,\n",
       "          \"u'day\": 1,\n",
       "          \"u'good\": 1,\n",
       "          \"u'have\": 1,\n",
       "          \"u'hello\": 1,\n",
       "          \"u'how\": 1,\n",
       "          \"u'nice\": 1,\n",
       "          \"u'world\": 1,\n",
       "          \"u'you\": 1,\n",
       "          \"uation+'\": 1,\n",
       "          'unsupervised': 1,\n",
       "          'up': 2,\n",
       "          'upload': 1,\n",
       "          'use': 4,\n",
       "          'used': 2,\n",
       "          'useful': 4,\n",
       "          'user': 1,\n",
       "          'using': 1,\n",
       "          'very': 2,\n",
       "          'vocabulary': 2,\n",
       "          'want': 1,\n",
       "          'we': 9,\n",
       "          'while': 1,\n",
       "          'will': 1,\n",
       "          'with': 12,\n",
       "          'with456': 3,\n",
       "          'word': 2,\n",
       "          'word.lower': 1,\n",
       "          'words': 7,\n",
       "          'world': 1,\n",
       "          'you': 4,\n",
       "          '{': 2,\n",
       "          '}': 2,\n",
       "          '•': 10})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.book.FreqDist(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n",
      "None\n",
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "\n",
    "#Moby Dick by Herman Melville 1851\n",
    "print (text1.similar(\"monstrous\"))\n",
    "\n",
    "#Sense and Sensibility by Jane Austen 1811\n",
    "print(text2.similar(\"monstrous\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *\n",
    "#Moby Dick by Herman Melville 1851\n",
    "fdist = FreqDist(text1)\n",
    "vocabulary = fdist.keys() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'[': 3,\n",
       "          'Moby': 84,\n",
       "          'Dick': 84,\n",
       "          'by': 1137,\n",
       "          'Herman': 1,\n",
       "          'Melville': 1,\n",
       "          '1851': 3,\n",
       "          ']': 1,\n",
       "          'ETYMOLOGY': 1,\n",
       "          '.': 6862,\n",
       "          '(': 210,\n",
       "          'Supplied': 2,\n",
       "          'a': 4569,\n",
       "          'Late': 1,\n",
       "          'Consumptive': 1,\n",
       "          'Usher': 2,\n",
       "          'to': 4542,\n",
       "          'Grammar': 2,\n",
       "          'School': 1,\n",
       "          ')': 78,\n",
       "          'The': 612,\n",
       "          'pale': 18,\n",
       "          '--': 1070,\n",
       "          'threadbare': 1,\n",
       "          'in': 3916,\n",
       "          'coat': 28,\n",
       "          ',': 18713,\n",
       "          'heart': 90,\n",
       "          'body': 110,\n",
       "          'and': 6024,\n",
       "          'brain': 37,\n",
       "          ';': 4072,\n",
       "          'I': 2124,\n",
       "          'see': 253,\n",
       "          'him': 1058,\n",
       "          'now': 646,\n",
       "          'He': 230,\n",
       "          'was': 1632,\n",
       "          'ever': 203,\n",
       "          'dusting': 2,\n",
       "          'his': 2459,\n",
       "          'old': 436,\n",
       "          'lexicons': 1,\n",
       "          'grammars': 2,\n",
       "          'with': 1659,\n",
       "          'queer': 44,\n",
       "          'handkerchief': 5,\n",
       "          'mockingly': 1,\n",
       "          'embellished': 3,\n",
       "          'all': 1462,\n",
       "          'the': 13721,\n",
       "          'gay': 13,\n",
       "          'flags': 1,\n",
       "          'of': 6536,\n",
       "          'known': 80,\n",
       "          'nations': 12,\n",
       "          'world': 173,\n",
       "          'loved': 3,\n",
       "          'dust': 10,\n",
       "          'it': 2209,\n",
       "          'somehow': 43,\n",
       "          'mildly': 10,\n",
       "          'reminded': 4,\n",
       "          'mortality': 1,\n",
       "          '\"': 1478,\n",
       "          'While': 30,\n",
       "          'you': 841,\n",
       "          'take': 118,\n",
       "          'hand': 205,\n",
       "          'school': 9,\n",
       "          'others': 37,\n",
       "          'teach': 5,\n",
       "          'them': 471,\n",
       "          'what': 442,\n",
       "          'name': 69,\n",
       "          'whale': 906,\n",
       "          '-': 2552,\n",
       "          'fish': 133,\n",
       "          'is': 1695,\n",
       "          'be': 1030,\n",
       "          'called': 116,\n",
       "          'our': 199,\n",
       "          'tongue': 11,\n",
       "          'leaving': 38,\n",
       "          'out': 529,\n",
       "          'through': 227,\n",
       "          'ignorance': 10,\n",
       "          'letter': 12,\n",
       "          'H': 2,\n",
       "          'which': 640,\n",
       "          'almost': 186,\n",
       "          'alone': 37,\n",
       "          'maketh': 5,\n",
       "          'signification': 1,\n",
       "          'word': 76,\n",
       "          'deliver': 3,\n",
       "          'that': 2982,\n",
       "          'not': 1103,\n",
       "          'true': 73,\n",
       "          '.\"': 489,\n",
       "          'HACKLUYT': 1,\n",
       "          'WHALE': 38,\n",
       "          '...': 11,\n",
       "          'Sw': 1,\n",
       "          'Dan': 4,\n",
       "          'HVAL': 1,\n",
       "          'This': 107,\n",
       "          'animal': 16,\n",
       "          'named': 11,\n",
       "          'from': 1052,\n",
       "          'roundness': 1,\n",
       "          'or': 697,\n",
       "          'rolling': 35,\n",
       "          'for': 1414,\n",
       "          'HVALT': 2,\n",
       "          'arched': 10,\n",
       "          'vaulted': 2,\n",
       "          'WEBSTER': 2,\n",
       "          \"'\": 2684,\n",
       "          'S': 63,\n",
       "          'DICTIONARY': 3,\n",
       "          'It': 310,\n",
       "          'more': 501,\n",
       "          'immediately': 14,\n",
       "          'Dut': 1,\n",
       "          'Ger': 1,\n",
       "          'WALLEN': 1,\n",
       "          'A': 167,\n",
       "          'WALW': 1,\n",
       "          'IAN': 1,\n",
       "          'roll': 16,\n",
       "          'wallow': 3,\n",
       "          'RICHARDSON': 1,\n",
       "          'KETOS': 1,\n",
       "          'GREEK': 1,\n",
       "          'CETUS': 1,\n",
       "          'LATIN': 1,\n",
       "          'WHOEL': 1,\n",
       "          'ANGLO': 1,\n",
       "          'SAXON': 1,\n",
       "          'DANISH': 2,\n",
       "          'WAL': 1,\n",
       "          'DUTCH': 2,\n",
       "          'HWAL': 1,\n",
       "          'SWEDISH': 1,\n",
       "          'ICELANDIC': 1,\n",
       "          'ENGLISH': 3,\n",
       "          'BALEINE': 1,\n",
       "          'FRENCH': 5,\n",
       "          'BALLENA': 1,\n",
       "          'SPANISH': 4,\n",
       "          'PEKEE': 2,\n",
       "          'NUEE': 4,\n",
       "          'FEGEE': 1,\n",
       "          'ERROMANGOAN': 1,\n",
       "          'EXTRACTS': 2,\n",
       "          'Sub': 7,\n",
       "          'Librarian': 1,\n",
       "          ').': 15,\n",
       "          'will': 379,\n",
       "          'seen': 161,\n",
       "          'this': 1280,\n",
       "          'mere': 42,\n",
       "          'painstaking': 1,\n",
       "          'burrower': 1,\n",
       "          'grub': 1,\n",
       "          'worm': 5,\n",
       "          'poor': 106,\n",
       "          'devil': 51,\n",
       "          'appears': 7,\n",
       "          'have': 760,\n",
       "          'gone': 58,\n",
       "          'long': 318,\n",
       "          'Vaticans': 1,\n",
       "          'street': 10,\n",
       "          'stalls': 1,\n",
       "          'earth': 46,\n",
       "          'picking': 4,\n",
       "          'up': 505,\n",
       "          'whatever': 44,\n",
       "          'random': 5,\n",
       "          'allusions': 7,\n",
       "          'whales': 237,\n",
       "          'he': 1661,\n",
       "          'could': 215,\n",
       "          'anyways': 2,\n",
       "          'find': 55,\n",
       "          'any': 320,\n",
       "          'book': 38,\n",
       "          'whatsoever': 5,\n",
       "          'sacred': 7,\n",
       "          'profane': 4,\n",
       "          'Therefore': 11,\n",
       "          'must': 282,\n",
       "          'every': 222,\n",
       "          'case': 69,\n",
       "          'at': 1231,\n",
       "          'least': 75,\n",
       "          'higgledy': 1,\n",
       "          'piggledy': 1,\n",
       "          'statements': 4,\n",
       "          'however': 80,\n",
       "          'authentic': 3,\n",
       "          'these': 381,\n",
       "          'extracts': 4,\n",
       "          'veritable': 4,\n",
       "          'gospel': 1,\n",
       "          'cetology': 4,\n",
       "          'Far': 4,\n",
       "          'As': 120,\n",
       "          'touching': 45,\n",
       "          'ancient': 28,\n",
       "          'authors': 3,\n",
       "          'generally': 30,\n",
       "          'as': 1620,\n",
       "          'well': 174,\n",
       "          'poets': 3,\n",
       "          'here': 272,\n",
       "          'appearing': 3,\n",
       "          'are': 586,\n",
       "          'solely': 6,\n",
       "          'valuable': 11,\n",
       "          'entertaining': 2,\n",
       "          'affording': 2,\n",
       "          'glancing': 12,\n",
       "          'bird': 17,\n",
       "          's': 1739,\n",
       "          'eye': 88,\n",
       "          'view': 46,\n",
       "          'has': 287,\n",
       "          'been': 415,\n",
       "          'promiscuously': 1,\n",
       "          'said': 302,\n",
       "          'thought': 149,\n",
       "          'fancied': 9,\n",
       "          'sung': 2,\n",
       "          'Leviathan': 64,\n",
       "          'many': 161,\n",
       "          'generations': 6,\n",
       "          'including': 8,\n",
       "          'own': 205,\n",
       "          'So': 147,\n",
       "          'fare': 10,\n",
       "          'thee': 129,\n",
       "          'whose': 86,\n",
       "          'commentator': 1,\n",
       "          'am': 86,\n",
       "          'Thou': 39,\n",
       "          'belongest': 1,\n",
       "          'hopeless': 8,\n",
       "          'sallow': 1,\n",
       "          'tribe': 9,\n",
       "          'no': 484,\n",
       "          'wine': 12,\n",
       "          'warm': 24,\n",
       "          'whom': 43,\n",
       "          'even': 181,\n",
       "          'Pale': 1,\n",
       "          'Sherry': 1,\n",
       "          'would': 421,\n",
       "          'too': 184,\n",
       "          'rosy': 2,\n",
       "          'strong': 34,\n",
       "          'but': 1113,\n",
       "          'one': 889,\n",
       "          'sometimes': 81,\n",
       "          'loves': 1,\n",
       "          'sit': 16,\n",
       "          'feel': 56,\n",
       "          'devilish': 9,\n",
       "          'grow': 24,\n",
       "          'convivial': 4,\n",
       "          'upon': 538,\n",
       "          'tears': 6,\n",
       "          'say': 237,\n",
       "          'bluntly': 1,\n",
       "          'full': 121,\n",
       "          'eyes': 155,\n",
       "          'empty': 22,\n",
       "          'glasses': 10,\n",
       "          'altogether': 29,\n",
       "          'unpleasant': 3,\n",
       "          'sadness': 2,\n",
       "          'Give': 15,\n",
       "          'Subs': 1,\n",
       "          '!': 1269,\n",
       "          'For': 197,\n",
       "          'how': 187,\n",
       "          'much': 218,\n",
       "          'pains': 15,\n",
       "          'ye': 460,\n",
       "          'please': 12,\n",
       "          'so': 918,\n",
       "          'shall': 84,\n",
       "          'go': 182,\n",
       "          'thankless': 1,\n",
       "          'Would': 11,\n",
       "          'clear': 39,\n",
       "          'Hampton': 1,\n",
       "          'Court': 1,\n",
       "          'Tuileries': 3,\n",
       "          'But': 705,\n",
       "          'gulp': 2,\n",
       "          'down': 364,\n",
       "          'your': 240,\n",
       "          'hie': 1,\n",
       "          'aloft': 53,\n",
       "          'royal': 29,\n",
       "          'mast': 124,\n",
       "          'hearts': 29,\n",
       "          'friends': 16,\n",
       "          'who': 319,\n",
       "          'before': 293,\n",
       "          'clearing': 4,\n",
       "          'seven': 15,\n",
       "          'storied': 4,\n",
       "          'heavens': 17,\n",
       "          'making': 45,\n",
       "          'refugees': 1,\n",
       "          'pampered': 1,\n",
       "          'Gabriel': 20,\n",
       "          'Michael': 1,\n",
       "          'Raphael': 1,\n",
       "          'against': 132,\n",
       "          'coming': 50,\n",
       "          'Here': 49,\n",
       "          'strike': 28,\n",
       "          'splintered': 7,\n",
       "          'together': 64,\n",
       "          'there': 715,\n",
       "          'unsplinterable': 1,\n",
       "          'And': 369,\n",
       "          'God': 132,\n",
       "          'created': 6,\n",
       "          'great': 293,\n",
       "          'GENESIS': 1,\n",
       "          'path': 10,\n",
       "          'shine': 3,\n",
       "          'after': 252,\n",
       "          'One': 28,\n",
       "          'think': 111,\n",
       "          'deep': 69,\n",
       "          'hoary': 2,\n",
       "          'JOB': 1,\n",
       "          'Now': 139,\n",
       "          'Lord': 44,\n",
       "          'had': 767,\n",
       "          'prepared': 12,\n",
       "          'swallow': 10,\n",
       "          'Jonah': 84,\n",
       "          'JONAH': 1,\n",
       "          'There': 147,\n",
       "          'ships': 87,\n",
       "          'thou': 232,\n",
       "          'hast': 19,\n",
       "          'made': 178,\n",
       "          'play': 29,\n",
       "          'therein': 5,\n",
       "          'PSALMS': 2,\n",
       "          'In': 237,\n",
       "          'day': 172,\n",
       "          'sore': 3,\n",
       "          'sword': 23,\n",
       "          'punish': 1,\n",
       "          'piercing': 4,\n",
       "          'serpent': 4,\n",
       "          'crooked': 8,\n",
       "          'slay': 4,\n",
       "          'dragon': 5,\n",
       "          'sea': 433,\n",
       "          'ISAIAH': 1,\n",
       "          'thing': 188,\n",
       "          'soever': 1,\n",
       "          'besides': 20,\n",
       "          'cometh': 1,\n",
       "          'within': 78,\n",
       "          'chaos': 4,\n",
       "          'monster': 49,\n",
       "          'mouth': 60,\n",
       "          'beast': 4,\n",
       "          'boat': 330,\n",
       "          'stone': 18,\n",
       "          'goes': 54,\n",
       "          'incontinently': 1,\n",
       "          'foul': 11,\n",
       "          'perisheth': 1,\n",
       "          'bottomless': 7,\n",
       "          'gulf': 4,\n",
       "          'paunch': 2,\n",
       "          'HOLLAND': 2,\n",
       "          'PLUTARCH': 1,\n",
       "          'MORALS': 1,\n",
       "          'Indian': 57,\n",
       "          'Sea': 22,\n",
       "          'breedeth': 1,\n",
       "          'most': 277,\n",
       "          'biggest': 2,\n",
       "          'fishes': 3,\n",
       "          ':': 162,\n",
       "          'among': 158,\n",
       "          'Whales': 29,\n",
       "          'Whirlpooles': 1,\n",
       "          'Balaene': 1,\n",
       "          'length': 78,\n",
       "          'four': 74,\n",
       "          'acres': 3,\n",
       "          'arpens': 1,\n",
       "          'land': 78,\n",
       "          'PLINY': 1,\n",
       "          'Scarcely': 1,\n",
       "          'we': 413,\n",
       "          'proceeded': 6,\n",
       "          'two': 285,\n",
       "          'days': 80,\n",
       "          'on': 1005,\n",
       "          'when': 553,\n",
       "          'about': 304,\n",
       "          'sunrise': 11,\n",
       "          'other': 412,\n",
       "          'monsters': 9,\n",
       "          'appeared': 10,\n",
       "          'Among': 8,\n",
       "          'former': 20,\n",
       "          'monstrous': 10,\n",
       "          'size': 12,\n",
       "          'came': 130,\n",
       "          'towards': 107,\n",
       "          'us': 228,\n",
       "          'open': 75,\n",
       "          'mouthed': 4,\n",
       "          'raising': 4,\n",
       "          'waves': 48,\n",
       "          'sides': 28,\n",
       "          'beating': 11,\n",
       "          'into': 520,\n",
       "          'foam': 19,\n",
       "          'TOOKE': 1,\n",
       "          'LUCIAN': 1,\n",
       "          'THE': 98,\n",
       "          'TRUE': 1,\n",
       "          'HISTORY': 4,\n",
       "          'visited': 7,\n",
       "          'country': 25,\n",
       "          'also': 88,\n",
       "          'catching': 7,\n",
       "          'horse': 26,\n",
       "          'bones': 48,\n",
       "          'very': 311,\n",
       "          'value': 6,\n",
       "          'their': 612,\n",
       "          'teeth': 47,\n",
       "          'brought': 38,\n",
       "          'some': 578,\n",
       "          'king': 25,\n",
       "          'best': 62,\n",
       "          'were': 680,\n",
       "          'catched': 1,\n",
       "          'forty': 28,\n",
       "          'eight': 24,\n",
       "          'fifty': 33,\n",
       "          'yards': 27,\n",
       "          'six': 31,\n",
       "          'killed': 33,\n",
       "          'sixty': 17,\n",
       "          'OTHER': 2,\n",
       "          'OR': 5,\n",
       "          'OCTHER': 1,\n",
       "          'VERBAL': 1,\n",
       "          'NARRATIVE': 4,\n",
       "          'TAKEN': 1,\n",
       "          'DOWN': 2,\n",
       "          'FROM': 10,\n",
       "          'HIS': 17,\n",
       "          'MOUTH': 1,\n",
       "          'BY': 15,\n",
       "          'KING': 2,\n",
       "          'ALFRED': 1,\n",
       "          'D': 23,\n",
       "          '890': 1,\n",
       "          'whereas': 14,\n",
       "          'things': 132,\n",
       "          'whether': 76,\n",
       "          'vessel': 54,\n",
       "          'enter': 9,\n",
       "          'dreadful': 6,\n",
       "          'lost': 45,\n",
       "          'swallowed': 13,\n",
       "          'gudgeon': 1,\n",
       "          'retires': 1,\n",
       "          'security': 3,\n",
       "          'sleeps': 7,\n",
       "          'MONTAIGNE': 1,\n",
       "          'APOLOGY': 1,\n",
       "          'FOR': 6,\n",
       "          'RAIMOND': 1,\n",
       "          'SEBOND': 1,\n",
       "          'Let': 38,\n",
       "          'fly': 14,\n",
       "          'let': 120,\n",
       "          'Old': 11,\n",
       "          'Nick': 1,\n",
       "          'me': 627,\n",
       "          'if': 421,\n",
       "          'described': 8,\n",
       "          'noble': 44,\n",
       "          'prophet': 13,\n",
       "          'Moses': 2,\n",
       "          'life': 162,\n",
       "          'patient': 6,\n",
       "          'Job': 5,\n",
       "          'RABELAIS': 1,\n",
       "          'liver': 4,\n",
       "          'cartloads': 1,\n",
       "          'STOWE': 1,\n",
       "          'ANNALS': 1,\n",
       "          'seas': 80,\n",
       "          'seethe': 3,\n",
       "          'like': 624,\n",
       "          'boiling': 15,\n",
       "          'pan': 3,\n",
       "          'LORD': 1,\n",
       "          'BACON': 1,\n",
       "          'VERSION': 2,\n",
       "          'OF': 49,\n",
       "          'Touching': 1,\n",
       "          'bulk': 32,\n",
       "          'ork': 1,\n",
       "          'received': 26,\n",
       "          'nothing': 102,\n",
       "          'certain': 87,\n",
       "          'They': 78,\n",
       "          'exceeding': 12,\n",
       "          'fat': 12,\n",
       "          'insomuch': 2,\n",
       "          'an': 582,\n",
       "          'incredible': 9,\n",
       "          'quantity': 13,\n",
       "          'oil': 90,\n",
       "          'extracted': 5,\n",
       "          'IBID': 3,\n",
       "          'LIFE': 2,\n",
       "          'AND': 37,\n",
       "          'DEATH': 1,\n",
       "          'sovereignest': 1,\n",
       "          'parmacetti': 3,\n",
       "          'inward': 4,\n",
       "          'bruise': 1,\n",
       "          'HENRY': 2,\n",
       "          'Very': 11,\n",
       "          'HAMLET': 1,\n",
       "          'Which': 6,\n",
       "          'secure': 12,\n",
       "          'skill': 10,\n",
       "          'leach': 1,\n",
       "          'art': 39,\n",
       "          'Mote': 1,\n",
       "          'availle': 1,\n",
       "          'returne': 1,\n",
       "          'againe': 1,\n",
       "          'To': 62,\n",
       "          'wound': 17,\n",
       "          'worker': 1,\n",
       "          'lowly': 8,\n",
       "          'dart': 24,\n",
       "          'Dinting': 1,\n",
       "          'breast': 7,\n",
       "          'bred': 9,\n",
       "          'restless': 4,\n",
       "          'paine': 1,\n",
       "          'Like': 23,\n",
       "          'wounded': 9,\n",
       "          'shore': 23,\n",
       "          'flies': 7,\n",
       "          'thro': 1,\n",
       "          'maine': 1,\n",
       "          'FAERIE': 1,\n",
       "          'QUEEN': 2,\n",
       "          'Immense': 1,\n",
       "          'motion': 17,\n",
       "          'vast': 73,\n",
       "          'bodies': 9,\n",
       "          'can': 220,\n",
       "          'peaceful': 6,\n",
       "          'calm': 41,\n",
       "          'trouble': 11,\n",
       "          'ocean': 71,\n",
       "          'til': 1,\n",
       "          'boil': 2,\n",
       "          'SIR': 4,\n",
       "          'WILLIAM': 2,\n",
       "          'DAVENANT': 1,\n",
       "          'PREFACE': 1,\n",
       "          'TO': 21,\n",
       "          'GONDIBERT': 1,\n",
       "          'What': 174,\n",
       "          'spermacetti': 1,\n",
       "          'men': 236,\n",
       "          'might': 183,\n",
       "          'justly': 3,\n",
       "          'doubt': 32,\n",
       "          'since': 63,\n",
       "          'learned': 25,\n",
       "          'Hosmannus': 1,\n",
       "          'work': 62,\n",
       "          'thirty': 26,\n",
       "          'years': 94,\n",
       "          'saith': 5,\n",
       "          'plainly': 39,\n",
       "          'Nescio': 1,\n",
       "          'quid': 2,\n",
       "          'T': 8,\n",
       "          'BROWNE': 3,\n",
       "          'SPERMA': 2,\n",
       "          'CETI': 2,\n",
       "          'VIDE': 1,\n",
       "          'V': 6,\n",
       "          'E': 5,\n",
       "          'Spencer': 1,\n",
       "          'Talus': 1,\n",
       "          'modern': 18,\n",
       "          'flail': 1,\n",
       "          'threatens': 1,\n",
       "          'ruin': 5,\n",
       "          'ponderous': 13,\n",
       "          'tail': 78,\n",
       "          'Their': 6,\n",
       "          'fixed': 37,\n",
       "          'jav': 1,\n",
       "          'lins': 1,\n",
       "          'side': 208,\n",
       "          'wears': 7,\n",
       "          'back': 151,\n",
       "          'grove': 3,\n",
       "          'pikes': 2,\n",
       "          'WALLER': 1,\n",
       "          'BATTLE': 2,\n",
       "          'SUMMER': 1,\n",
       "          'ISLANDS': 1,\n",
       "          'By': 52,\n",
       "          'Commonwealth': 1,\n",
       "          'State': 4,\n",
       "          '--(': 4,\n",
       "          'Latin': 4,\n",
       "          'Civitas': 1,\n",
       "          'artificial': 5,\n",
       "          'man': 508,\n",
       "          'OPENING': 1,\n",
       "          'SENTENCE': 1,\n",
       "          'HOBBES': 1,\n",
       "          'LEVIATHAN': 1,\n",
       "          'Silly': 1,\n",
       "          'Mansoul': 1,\n",
       "          'without': 154,\n",
       "          'chewing': 1,\n",
       "          'sprat': 1,\n",
       "          'PILGRIM': 1,\n",
       "          'PROGRESS': 1,\n",
       "          'That': 85,\n",
       "          'works': 30,\n",
       "          'Created': 1,\n",
       "          'hugest': 3,\n",
       "          'swim': 20,\n",
       "          'stream': 11,\n",
       "          'PARADISE': 1,\n",
       "          'LOST': 1,\n",
       "          '---\"': 1,\n",
       "          'Hugest': 1,\n",
       "          'living': 73,\n",
       "          'creatures': 34,\n",
       "          'Stretched': 1,\n",
       "          'promontory': 5,\n",
       "          'swims': 8,\n",
       "          'seems': 84,\n",
       "          'moving': 13,\n",
       "          'gills': 4,\n",
       "          'Draws': 1,\n",
       "          'breath': 18,\n",
       "          'spouts': 16,\n",
       "          'mighty': 47,\n",
       "          'water': 185,\n",
       "          'swimming': 29,\n",
       "          'FULLLER': 1,\n",
       "          'PROFANE': 1,\n",
       "          'HOLY': 1,\n",
       "          'STATE': 1,\n",
       "          'close': 54,\n",
       "          'behind': 50,\n",
       "          'lie': 26,\n",
       "          'huge': 29,\n",
       "          'attend': 9,\n",
       "          'prey': 14,\n",
       "          'give': 71,\n",
       "          'chance': 46,\n",
       "          'fry': 3,\n",
       "          'gaping': 3,\n",
       "          'jaws': 30,\n",
       "          'mistake': 9,\n",
       "          'way': 269,\n",
       "          'DRYDEN': 1,\n",
       "          'ANNUS': 1,\n",
       "          'MIRABILIS': 1,\n",
       "          'floating': 24,\n",
       "          'stern': 48,\n",
       "          'ship': 507,\n",
       "          'they': 586,\n",
       "          'cut': 50,\n",
       "          'off': 217,\n",
       "          'head': 335,\n",
       "          'tow': 16,\n",
       "          'near': 69,\n",
       "          'come': 150,\n",
       "          'aground': 1,\n",
       "          'twelve': 16,\n",
       "          'thirteen': 2,\n",
       "          'feet': 125,\n",
       "          'THOMAS': 3,\n",
       "          'EDGE': 1,\n",
       "          'TEN': 1,\n",
       "          'VOYAGES': 3,\n",
       "          'SPITZBERGEN': 1,\n",
       "          'IN': 19,\n",
       "          'PURCHAS': 1,\n",
       "          'saw': 115,\n",
       "          'sporting': 4,\n",
       "          'wantonness': 1,\n",
       "          'fuzzing': 1,\n",
       "          'pipes': 8,\n",
       "          'vents': 1,\n",
       "          'nature': 34,\n",
       "          'placed': 36,\n",
       "          'shoulders': 13,\n",
       "          'HERBERT': 1,\n",
       "          'INTO': 1,\n",
       "          'ASIA': 1,\n",
       "          'AFRICA': 1,\n",
       "          'HARRIS': 2,\n",
       "          'COLL': 2,\n",
       "          'such': 336,\n",
       "          'troops': 2,\n",
       "          'forced': 18,\n",
       "          'proceed': 14,\n",
       "          'deal': 12,\n",
       "          'caution': 2,\n",
       "          'fear': 32,\n",
       "          'should': 181,\n",
       "          'run': 51,\n",
       "          'SCHOUTEN': 1,\n",
       "          'SIXTH': 1,\n",
       "          'CIRCUMNAVIGATION': 1,\n",
       "          'We': 47,\n",
       "          'set': 74,\n",
       "          'sail': 96,\n",
       "          'Elbe': 1,\n",
       "          'wind': 67,\n",
       "          'N': 2,\n",
       "          'Jonas': 3,\n",
       "          'Whale': 282,\n",
       "          'Some': 38,\n",
       "          't': 283,\n",
       "          'fable': 5,\n",
       "          'frequently': 14,\n",
       "          'climb': 4,\n",
       "          'masts': 26,\n",
       "          'first': 210,\n",
       "          'discoverer': 2,\n",
       "          'ducat': 1,\n",
       "          'told': 45,\n",
       "          'taken': 50,\n",
       "          'Shetland': 2,\n",
       "          'above': 56,\n",
       "          'barrel': 5,\n",
       "          'herrings': 1,\n",
       "          'belly': 9,\n",
       "          'harpooneers': 55,\n",
       "          'caught': 44,\n",
       "          'once': 144,\n",
       "          'Spitzbergen': 4,\n",
       "          'white': 191,\n",
       "          'over': 403,\n",
       "          'VOYAGE': 7,\n",
       "          'GREENLAND': 1,\n",
       "          '1671': 2,\n",
       "          'Several': 1,\n",
       "          'coast': 40,\n",
       "          'Fife': 1,\n",
       "          'Anno': 1,\n",
       "          '1652': 1,\n",
       "          'eighty': 4,\n",
       "          'bone': 50,\n",
       "          'kind': 27,\n",
       "          'informed': 4,\n",
       "          '),': 62,\n",
       "          'did': 246,\n",
       "          'afford': 9,\n",
       "          '500': 2,\n",
       "          'weight': 17,\n",
       "          'baleen': 11,\n",
       "          'stand': 83,\n",
       "          'gate': 4,\n",
       "          'garden': 6,\n",
       "          'Pitferren': 1,\n",
       "          'SIBBALD': 1,\n",
       "          'FIFE': 1,\n",
       "          'KINROSS': 1,\n",
       "          'Myself': 1,\n",
       "          'agreed': 3,\n",
       "          'try': 49,\n",
       "          'master': 23,\n",
       "          'kill': 30,\n",
       "          'Sperma': 1,\n",
       "          'ceti': 1,\n",
       "          'never': 195,\n",
       "          'hear': 60,\n",
       "          'sort': 152,\n",
       "          'fierceness': 1,\n",
       "          'swiftness': 6,\n",
       "          'RICHARD': 1,\n",
       "          'STRAFFORD': 1,\n",
       "          'LETTER': 1,\n",
       "          'BERMUDAS': 1,\n",
       "          'PHIL': 1,\n",
       "          'TRANS': 1,\n",
       "          '1668': 1,\n",
       "          'voice': 46,\n",
       "          'obey': 8,\n",
       "          'PRIMER': 1,\n",
       "          'abundance': 4,\n",
       "          'large': 77,\n",
       "          'being': 219,\n",
       "          'those': 297,\n",
       "          'southern': 5,\n",
       "          'may': 230,\n",
       "          'hundred': 50,\n",
       "          'than': 309,\n",
       "          'northward': 4,\n",
       "          'CAPTAIN': 2,\n",
       "          'COWLEY': 1,\n",
       "          'ROUND': 2,\n",
       "          'GLOBE': 4,\n",
       "          '1729': 1,\n",
       "          '\"...': 1,\n",
       "          'frequendy': 1,\n",
       "          'attended': 6,\n",
       "          'insupportable': 1,\n",
       "          'smell': 11,\n",
       "          'bring': 18,\n",
       "          'disorder': 1,\n",
       "          'ULLOA': 1,\n",
       "          'SOUTH': 1,\n",
       "          'AMERICA': 1,\n",
       "          'chosen': 3,\n",
       "          'sylphs': 1,\n",
       "          'special': 15,\n",
       "          'note': 6,\n",
       "          'trust': 4,\n",
       "          'important': 19,\n",
       "          'charge': 10,\n",
       "          'petticoat': 1,\n",
       "          'Oft': 1,\n",
       "          'fold': 6,\n",
       "          'fence': 2,\n",
       "          'fail': 17,\n",
       "          'Tho': 1,\n",
       "          'stuffed': 5,\n",
       "          'hoops': 11,\n",
       "          'armed': 15,\n",
       "          'ribs': 20,\n",
       "          'RAPE': 1,\n",
       "          'LOCK': 1,\n",
       "          'If': 60,\n",
       "          'compare': 7,\n",
       "          'animals': 5,\n",
       "          'respect': 16,\n",
       "          'magnitude': 21,\n",
       "          'abode': 2,\n",
       "          'appear': 6,\n",
       "          'contemptible': 4,\n",
       "          'comparison': 6,\n",
       "          'doubtless': 12,\n",
       "          'largest': 19,\n",
       "          'creation': 7,\n",
       "          'GOLDSMITH': 2,\n",
       "          'NAT': 1,\n",
       "          'HIST': 2,\n",
       "          'write': 5,\n",
       "          'little': 247,\n",
       "          'make': 109,\n",
       "          'speak': 47,\n",
       "          'wales': 1,\n",
       "          'JOHNSON': 1,\n",
       "          'afternoon': 10,\n",
       "          'supposed': 15,\n",
       "          'rock': 14,\n",
       "          'found': 115,\n",
       "          'dead': 90,\n",
       "          'Asiatics': 2,\n",
       "          'then': 571,\n",
       "          'towing': 14,\n",
       "          'ashore': 33,\n",
       "          'seemed': 283,\n",
       "          'endeavor': 4,\n",
       "          'conceal': 2,\n",
       "          'themselves': 59,\n",
       "          'order': 64,\n",
       "          'avoid': 6,\n",
       "          'COOK': 1,\n",
       "          'larger': 9,\n",
       "          'seldom': 24,\n",
       "          'venture': 5,\n",
       "          'attack': 8,\n",
       "          'dread': 12,\n",
       "          'afraid': 15,\n",
       "          'mention': 15,\n",
       "          'names': 12,\n",
       "          'carry': 25,\n",
       "          'dung': 1,\n",
       "          'lime': 1,\n",
       "          'juniper': 1,\n",
       "          'wood': 34,\n",
       "          'articles': 10,\n",
       "          'same': 213,\n",
       "          'boats': 145,\n",
       "          'terrify': 3,\n",
       "          'prevent': 6,\n",
       "          'approach': 5,\n",
       "          'UNO': 1,\n",
       "          'VON': 1,\n",
       "          'TROIL': 1,\n",
       "          'LETTERS': 1,\n",
       "          'ON': 11,\n",
       "          'BANKS': 1,\n",
       "          'SOLANDER': 1,\n",
       "          'ICELAND': 2,\n",
       "          '1772': 1,\n",
       "          'Spermacetti': 2,\n",
       "          'Nantuckois': 1,\n",
       "          'active': 8,\n",
       "          'fierce': 11,\n",
       "          'requires': 7,\n",
       "          'address': 4,\n",
       "          'boldness': 2,\n",
       "          'fishermen': 28,\n",
       "          'JEFFERSON': 1,\n",
       "          'MEMORIAL': 1,\n",
       "          'MINISTER': 1,\n",
       "          '1778': 2,\n",
       "          'pray': 6,\n",
       "          'sir': 143,\n",
       "          'equal': 14,\n",
       "          '?\"': 252,\n",
       "          'EDMUND': 2,\n",
       "          'BURKE': 2,\n",
       "          'REFERENCE': 1,\n",
       "          'PARLIAMENT': 1,\n",
       "          'NANTUCKET': 11,\n",
       "          'FISHERY': 2,\n",
       "          'Spain': 5,\n",
       "          'stranded': 12,\n",
       "          'shores': 7,\n",
       "          'Europe': 5,\n",
       "          'SOMEWHERE': 1,\n",
       "          '.)': 22,\n",
       "          'tenth': 4,\n",
       "          'branch': 4,\n",
       "          'ordinary': 19,\n",
       "          'revenue': 2,\n",
       "          'grounded': 3,\n",
       "          'consideration': 8,\n",
       "          'guarding': 1,\n",
       "          'protecting': 1,\n",
       "          'pirates': 9,\n",
       "          'robbers': 1,\n",
       "          'right': 97,\n",
       "          'sturgeon': 3,\n",
       "          'either': 39,\n",
       "          'thrown': 25,\n",
       "          'property': 7,\n",
       "          'BLACKSTONE': 1,\n",
       "          'Soon': 17,\n",
       "          'sport': 3,\n",
       "          'death': 71,\n",
       "          'crews': 16,\n",
       "          'repair': 3,\n",
       "          'Rodmond': 1,\n",
       "          'unerring': 3,\n",
       "          'o': 16,\n",
       "          'er': 7,\n",
       "          'suspends': 1,\n",
       "          'barbed': 6,\n",
       "          'steel': 32,\n",
       "          'turn': 54,\n",
       "          'attends': 1,\n",
       "          'FALCONER': 1,\n",
       "          'SHIPWRECK': 2,\n",
       "          'Bright': 1,\n",
       "          'shone': 3,\n",
       "          'roofs': 1,\n",
       "          'domes': 1,\n",
       "          'spires': 6,\n",
       "          'rockets': 1,\n",
       "          ...})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['animal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "tokens = word_tokenize(sentence)\n",
    "print( pos_tag(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  If/IN\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  out/IN\n",
      "  of/IN\n",
      "  my/PRP$\n",
      "  mind/NN\n",
      "  ,/,\n",
      "  it/PRP\n",
      "  's/VBZ\n",
      "  all/DT\n",
      "  right/NN\n",
      "  with/IN\n",
      "  me/PRP\n",
      "  ,/,\n",
      "  thought/VBD\n",
      "  (PERSON Moses/NNP Herzog/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "#Saul Bellow, Herzog (1964)\n",
    "sentence = \"If I am out of my mind, it's all right with me, thought Moses Herzog.\"\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print (nltk.ne_chunk(pos_tags, binary=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.ne_chunk(pos_tags, binary=False).draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = all_words.keys()\n",
    "\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "        contains(seagal) = True              neg : pos    =     12.9 : 1.0\n",
      "     contains(laughably) = True              neg : pos    =     12.2 : 1.0\n",
      "    contains(astounding) = True              pos : neg    =     11.8 : 1.0\n",
      "        contains(avoids) = True              pos : neg    =     11.8 : 1.0\n",
      "          contains(slip) = True              pos : neg    =     11.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "classifier.show_most_informative_features(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.943708609271523\n",
      "6.055555555555555\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import inaugural\n",
    "\n",
    "wash = inaugural.words('1789-Washington.txt')\n",
    "obama = inaugural.words('2009-Obama.txt')\n",
    "\n",
    "wash_word_lengths = [len(w) for w in set(v.lower() for v in wash)]\n",
    "print (sum(wash_word_lengths) * 1.0 / len(wash_word_lengths))\n",
    "\n",
    "obama_word_lengths = [len(w) for w in set(v.lower() for v in obama)]\n",
    "print (sum(obama_word_lengths) * 1.0 / len(obama_word_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'fellow', 'citizens', ':', 'I', 'stand', 'here', ...]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "cfd = nltk.ConditionalFreqDist((genre, word)\n",
    "        for genre in brown.categories()\n",
    "        for word in brown.words(categories=genre))\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category           can could   may might  must  will\n",
      "news                93    86    66    38    50   389\n",
      "religion            82    59    78    12    54    71\n",
      "hobbies            268    58   131    22    83   264\n",
      "science_fiction     16    49     4    12     8    16\n",
      "romance             74   193    11    51    45    43\n",
      "humor               16    30     8     8     9    13\n"
     ]
    }
   ],
   "source": [
    "def tabulate(cfdist, words, categories):\n",
    "    print ('%-16s' % 'Category',end='')\n",
    "    for word in words:                                  \n",
    "        print ('%6s' % word,end='')\n",
    "    print()\n",
    "    for category in categories:\n",
    "        print ('%-16s' % category,end='')                     \n",
    "        for word in words:                              \n",
    "            print( '%6d' % cfdist[category][word],end='')      \n",
    "        print()\n",
    "        \n",
    "tabulate((cfd), modals, genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "words =['the','quick','brown','fox',\n",
    "'jumps','over','the','lazy','dog']\n",
    "\n",
    "bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('brown', 'fox'),\n",
       " ('fox', 'jumps'),\n",
       " ('jumps', 'over'),\n",
       " ('lazy', 'dog'),\n",
       " ('quick', 'brown'),\n",
       " ('over', 'the'),\n",
       " ('the', 'lazy'),\n",
       " ('the', 'quick')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
