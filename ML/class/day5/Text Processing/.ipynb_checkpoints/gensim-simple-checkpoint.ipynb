{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",\".*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"text8.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' anarchism originated as a term of abuse first used against early working class radicals including t'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' collectively and that goods be distributed by need not labor an early anarchist communist was josep'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(10000)\n",
    "f.read(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.Text8Corpus('./text8.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 16:46:24,181 : INFO : collecting all words and their counts\n",
      "2019-02-06 16:46:24,184 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-02-06 16:46:28,365 : INFO : collected 253854 word types from a corpus of 17005207 raw words and 1701 sentences\n",
      "2019-02-06 16:46:28,365 : INFO : Loading a fresh vocabulary\n",
      "2019-02-06 16:46:28,581 : INFO : effective_min_count=5 retains 71290 unique words (28% of original 253854, drops 182564)\n",
      "2019-02-06 16:46:28,581 : INFO : effective_min_count=5 leaves 16718844 word corpus (98% of original 17005207, drops 286363)\n",
      "2019-02-06 16:46:28,747 : INFO : deleting the raw counts dictionary of 253854 items\n",
      "2019-02-06 16:46:28,747 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2019-02-06 16:46:28,747 : INFO : downsampling leaves estimated 12506280 word corpus (74.8% of prior 16718844)\n",
      "2019-02-06 16:46:28,948 : INFO : estimated required memory for 71290 words and 200 dimensions: 149709000 bytes\n",
      "2019-02-06 16:46:28,948 : INFO : resetting layer weights\n",
      "2019-02-06 16:46:29,667 : INFO : training model with 3 workers on 71290 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-06 16:46:30,673 : INFO : EPOCH 1 - PROGRESS: at 7.82% examples, 968494 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:31,683 : INFO : EPOCH 1 - PROGRESS: at 16.52% examples, 1024004 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:32,694 : INFO : EPOCH 1 - PROGRESS: at 25.10% examples, 1040773 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-06 16:46:33,687 : INFO : EPOCH 1 - PROGRESS: at 33.63% examples, 1050576 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:34,699 : INFO : EPOCH 1 - PROGRESS: at 42.27% examples, 1056578 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:35,700 : INFO : EPOCH 1 - PROGRESS: at 50.79% examples, 1059013 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:36,703 : INFO : EPOCH 1 - PROGRESS: at 58.67% examples, 1048131 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:37,706 : INFO : EPOCH 1 - PROGRESS: at 66.84% examples, 1045238 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:38,707 : INFO : EPOCH 1 - PROGRESS: at 74.60% examples, 1037378 words/s, in_qsize 4, out_qsize 0\n",
      "2019-02-06 16:46:39,710 : INFO : EPOCH 1 - PROGRESS: at 82.30% examples, 1027714 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:40,699 : INFO : EPOCH 1 - PROGRESS: at 90.89% examples, 1031770 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:41,717 : INFO : EPOCH 1 - PROGRESS: at 99.41% examples, 1033591 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:41,777 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-06 16:46:41,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-06 16:46:41,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-06 16:46:41,787 : INFO : EPOCH - 1 : training on 17005207 raw words (12507563 effective words) took 12.1s, 1033568 effective words/s\n",
      "2019-02-06 16:46:42,791 : INFO : EPOCH 2 - PROGRESS: at 8.23% examples, 1019884 words/s, in_qsize 4, out_qsize 0\n",
      "2019-02-06 16:46:43,788 : INFO : EPOCH 2 - PROGRESS: at 16.93% examples, 1048756 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:44,809 : INFO : EPOCH 2 - PROGRESS: at 25.63% examples, 1059941 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-06 16:46:45,810 : INFO : EPOCH 2 - PROGRESS: at 34.27% examples, 1065555 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:46,813 : INFO : EPOCH 2 - PROGRESS: at 42.92% examples, 1069747 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:47,815 : INFO : EPOCH 2 - PROGRESS: at 51.56% examples, 1071478 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:48,825 : INFO : EPOCH 2 - PROGRESS: at 59.91% examples, 1067935 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:49,836 : INFO : EPOCH 2 - PROGRESS: at 68.25% examples, 1063793 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:50,834 : INFO : EPOCH 2 - PROGRESS: at 76.90% examples, 1064121 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:51,836 : INFO : EPOCH 2 - PROGRESS: at 85.54% examples, 1065112 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:52,841 : INFO : EPOCH 2 - PROGRESS: at 93.83% examples, 1060718 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:53,611 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-06 16:46:53,623 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-06 16:46:53,626 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-06 16:46:53,626 : INFO : EPOCH - 2 : training on 17005207 raw words (12505812 effective words) took 11.8s, 1056532 effective words/s\n",
      "2019-02-06 16:46:54,637 : INFO : EPOCH 3 - PROGRESS: at 7.76% examples, 958081 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:55,641 : INFO : EPOCH 3 - PROGRESS: at 15.81% examples, 978404 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:56,628 : INFO : EPOCH 3 - PROGRESS: at 23.93% examples, 992080 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:57,632 : INFO : EPOCH 3 - PROGRESS: at 32.33% examples, 1008850 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:58,637 : INFO : EPOCH 3 - PROGRESS: at 40.92% examples, 1022786 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:46:59,648 : INFO : EPOCH 3 - PROGRESS: at 49.50% examples, 1031843 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:00,651 : INFO : EPOCH 3 - PROGRESS: at 58.02% examples, 1036211 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:01,662 : INFO : EPOCH 3 - PROGRESS: at 66.08% examples, 1032037 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:02,658 : INFO : EPOCH 3 - PROGRESS: at 74.60% examples, 1036290 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:03,667 : INFO : EPOCH 3 - PROGRESS: at 83.19% examples, 1037576 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-06 16:47:04,657 : INFO : EPOCH 3 - PROGRESS: at 91.12% examples, 1033556 words/s, in_qsize 4, out_qsize 0\n",
      "2019-02-06 16:47:05,678 : INFO : EPOCH 3 - PROGRESS: at 99.29% examples, 1030929 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-06 16:47:05,753 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-06 16:47:05,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-06 16:47:05,773 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-06 16:47:05,773 : INFO : EPOCH - 3 : training on 17005207 raw words (12508677 effective words) took 12.1s, 1030158 effective words/s\n",
      "2019-02-06 16:47:06,779 : INFO : EPOCH 4 - PROGRESS: at 8.23% examples, 1020697 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:07,780 : INFO : EPOCH 4 - PROGRESS: at 16.40% examples, 1017929 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-06 16:47:08,779 : INFO : EPOCH 4 - PROGRESS: at 24.10% examples, 999969 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:09,775 : INFO : EPOCH 4 - PROGRESS: at 31.80% examples, 992604 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:10,789 : INFO : EPOCH 4 - PROGRESS: at 39.56% examples, 987382 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:11,791 : INFO : EPOCH 4 - PROGRESS: at 46.80% examples, 973981 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:12,791 : INFO : EPOCH 4 - PROGRESS: at 54.56% examples, 973948 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:13,809 : INFO : EPOCH 4 - PROGRESS: at 61.85% examples, 965806 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:14,815 : INFO : EPOCH 4 - PROGRESS: at 69.31% examples, 961872 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:15,816 : INFO : EPOCH 4 - PROGRESS: at 77.07% examples, 961462 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:16,817 : INFO : EPOCH 4 - PROGRESS: at 85.48% examples, 969039 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-06 16:47:17,825 : INFO : EPOCH 4 - PROGRESS: at 94.12% examples, 977460 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-06 16:47:18,492 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-06 16:47:18,506 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-06 16:47:18,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-06 16:47:18,511 : INFO : EPOCH - 4 : training on 17005207 raw words (12505202 effective words) took 12.7s, 982185 effective words/s\n",
      "2019-02-06 16:47:19,516 : INFO : EPOCH 5 - PROGRESS: at 8.35% examples, 1031164 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 16:47:20,519 : INFO : EPOCH 5 - PROGRESS: at 16.52% examples, 1023956 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:21,523 : INFO : EPOCH 5 - PROGRESS: at 24.69% examples, 1023561 words/s, in_qsize 6, out_qsize 1\n",
      "2019-02-06 16:47:22,540 : INFO : EPOCH 5 - PROGRESS: at 32.86% examples, 1022199 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:23,531 : INFO : EPOCH 5 - PROGRESS: at 41.03% examples, 1022952 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:24,547 : INFO : EPOCH 5 - PROGRESS: at 48.91% examples, 1016409 words/s, in_qsize 6, out_qsize 0\n",
      "2019-02-06 16:47:25,555 : INFO : EPOCH 5 - PROGRESS: at 56.38% examples, 1003834 words/s, in_qsize 4, out_qsize 1\n",
      "2019-02-06 16:47:26,569 : INFO : EPOCH 5 - PROGRESS: at 64.20% examples, 999690 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:27,572 : INFO : EPOCH 5 - PROGRESS: at 71.37% examples, 988421 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:28,577 : INFO : EPOCH 5 - PROGRESS: at 78.84% examples, 980771 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:29,581 : INFO : EPOCH 5 - PROGRESS: at 86.42% examples, 977246 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:30,583 : INFO : EPOCH 5 - PROGRESS: at 93.83% examples, 971422 words/s, in_qsize 5, out_qsize 0\n",
      "2019-02-06 16:47:31,333 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-06 16:47:31,338 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-06 16:47:31,340 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-06 16:47:31,341 : INFO : EPOCH - 5 : training on 17005207 raw words (12506861 effective words) took 12.8s, 975002 effective words/s\n",
      "2019-02-06 16:47:31,341 : INFO : training on a 85026035 raw words (62534115 effective words) took 61.7s, 1014198 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 16:49:32,278 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6607222557067871)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.7850480079650879),\n",
       " ('wife', 0.715831458568573),\n",
       " ('grandmother', 0.7051951885223389)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['girl', 'father'], ['boy'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'he' is to 'his' as 'she' is to 'her'\n",
      "'big' is to 'bigger' as 'bad' is to 'worse'\n",
      "'going' is to 'went' as 'being' is to 'was'\n"
     ]
    }
   ],
   "source": [
    "more_examples = [\"he his she\", \"big bigger bad\", \"going went being\"]\n",
    "for example in more_examples:\n",
    "     a, b, x = example.split()\n",
    "     predicted = model.most_similar([x, b], [a])[0][0]\n",
    "     print (\"'%s' is to '%s' as '%s' is to '%s'\" % (a, b, x, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
